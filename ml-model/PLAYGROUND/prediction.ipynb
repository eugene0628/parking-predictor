{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshmarcelin/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- feature1\n- feature2\nFeature names seen at fit time, yet now missing:\n- y1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m input_data \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# Add your features here. For example:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# ...\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Prepare the input data for prediction\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m request \u001b[39m=\u001b[39m prepare_single_request(input_data, scaler)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Make a prediction\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(request)\n",
      "\u001b[1;32m/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_single_request\u001b[39m(input_data, scaler):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Assuming 'input_data' is a dictionary with the necessary features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([input_data])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     scaled_data \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joshmarcelin/Stuff/school/capstone/project/parking-predictor/ml-model/PLAYGROUND/prediction.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([scaled_data])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:515\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[1;32m    503\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 515\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    516\u001b[0m     X,\n\u001b[1;32m    517\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    518\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    519\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    520\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    523\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    524\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- feature1\n- feature2\nFeature names seen at fit time, yet now missing:\n- y1\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Function to load a model\n",
    "def load_saved_model(model_path):\n",
    "    return load_model(model_path)\n",
    "\n",
    "# Function to load a scaler\n",
    "def load_saved_scaler(scaler_path):\n",
    "    return joblib.load(scaler_path)\n",
    "\n",
    "# Prepare a sequence of requests for prediction\n",
    "def prepare_sequence_request(sequence):\n",
    "    # 'sequence' is a list of lists, where each sublist represents a time step\n",
    "    # Since the data is already scaled, we just need to format it correctly\n",
    "    return np.array([sequence])  # Adding the batch dimension\n",
    "\n",
    "# Directories\n",
    "model_data_directory = 'model_data'\n",
    "scaler_data_directory = 'scaler_data'\n",
    "\n",
    "# Model and scaler file information\n",
    "models_and_scalers = {\n",
    "    'y1': ('model_y1.h5', 'scaler_y1.joblib'),\n",
    "    'y12': ('model_y12.h5', 'scaler_y12.joblib'),\n",
    "    'y14': ('model_y14.h5', 'scaler_y14.joblib')\n",
    "}\n",
    "\n",
    "# Loop through each model and scaler, load them, and make a prediction\n",
    "for target_column, (model_file, scaler_file) in models_and_scalers.items():\n",
    "    model_path = os.path.join(model_data_directory, model_file)\n",
    "    scaler_path = os.path.join(scaler_data_directory, scaler_file)\n",
    "\n",
    "    # Load model and scaler\n",
    "    model = load_saved_model(model_path)\n",
    "    scaler = load_saved_scaler(scaler_path)\n",
    "\n",
    "    sequence_data = [\n",
    "        [0.0, 2.0, 13.05],\n",
    "        [0.0, 2.0, 13.06666667],\n",
    "        [0.0, 2.0, 13.08333333],\n",
    "        [0.0, 2.0, 13.1],\n",
    "        [0.0, 2.0, 13.11666667]\n",
    "    ]\n",
    "\n",
    "    # Prepare the input data for prediction\n",
    "    request = prepare_sequence_request(sequence_data)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(request)\n",
    "    print(f'Prediction for model {target_column}: {prediction}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
